# Fase 4B â€” DetecciÃ³n Totalmente AutomÃ¡tica

## 1) Objetivo

Implementar detecciÃ³n automÃ¡tica de elementos de vela sin intervenciÃ³n del usuario, usando segmentaciÃ³n semÃ¡ntica y ML ligero (TensorFlow.js). El sistema detectarÃ¡ automÃ¡ticamente la vela, sus bordes (luff/leech), y las draft stripes visibles.

## 2) Contexto del dominio

Referencia: `docs/01-glossary.md`

Esta fase extiende la Fase 4A (semi-automÃ¡tica) para eliminar la necesidad de puntos ancla. El sistema debe:
- Identificar la regiÃ³n de la vela en la imagen
- Detectar automÃ¡ticamente draft stripes por contraste de color
- Extraer luff y leech sin intervenciÃ³n manual

## 3) Alcance

### Incluye
- IntegraciÃ³n de TensorFlow.js (WASM/WebGL backend)
- Modelo de segmentaciÃ³n ligero para detectar regiÃ³n de vela
- DetecciÃ³n de draft stripes por anÃ¡lisis de color/contraste
- DetecciÃ³n automÃ¡tica de luff/leech por geometrÃ­a
- Fallback a modo semi-automÃ¡tico si confianza < 70%
- ClasificaciÃ³n automÃ¡tica de tipo de escena

### No incluye
- Entrenamiento de modelos custom (usar transfer learning o modelos pre-entrenados)
- DetecciÃ³n de mÃºltiples velas en una imagen
- Tracking de vela en video
- OCR de nÃºmeros de vela

## 4) Datos

### Entidades afectadas

```typescript
// ExtensiÃ³n de PhotoAnalysis
interface PhotoAnalysis {
  sceneType: SceneType
  sailId?: string
  mastId?: string
  layers: PhotoLayer[]

  // NUEVO: Resultado de auto-detecciÃ³n
  autoDetection?: {
    timestamp: string
    modelVersion: string

    // RegiÃ³n de la vela detectada
    sailMask?: {
      boundingBox: { x: number; y: number; width: number; height: number }
      confidence: number
      polygonPoints: NormalizedPoint[]  // Contorno de la vela
    }

    // Draft stripes detectadas automÃ¡ticamente
    detectedStripes?: Array<{
      estimatedHeightPct: number        // Altura estimada en la vela
      points: NormalizedPoint[]         // PolilÃ­nea de la stripe
      confidence: number
      colorSignature: string            // Para matching con stripes definidas
    }>

    // Bordes detectados
    detectedEdges?: {
      luff?: { points: NormalizedPoint[]; confidence: number }
      leech?: { points: NormalizedPoint[]; confidence: number }
      foot?: { points: NormalizedPoint[]; confidence: number }
    }

    // Escena inferida
    inferredSceneType?: {
      type: SceneType
      confidence: number
      alternatives: Array<{ type: SceneType; confidence: number }>
    }
  }
}
```

## 5) Arquitectura tÃ©cnica

### 5.1 Estructura de archivos

```
apps/desktop/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ lib/
â”‚       â””â”€â”€ cv/
â”‚           â”œâ”€â”€ ... (existentes de Fase 4A)
â”‚           â”‚
â”‚           â””â”€â”€ ml/
â”‚               â”œâ”€â”€ index.ts              # Exportaciones
â”‚               â”œâ”€â”€ tfjs-loader.ts        # Carga TensorFlow.js
â”‚               â”œâ”€â”€ sail-segmenter.ts     # SegmentaciÃ³n de vela
â”‚               â”œâ”€â”€ stripe-detector.ts    # DetecciÃ³n de stripes
â”‚               â”œâ”€â”€ scene-classifier.ts   # ClasificaciÃ³n de escena
â”‚               â””â”€â”€ models/
â”‚                   â””â”€â”€ README.md         # Instrucciones para modelos
â”‚
â”œâ”€â”€ public/
â”‚   â””â”€â”€ models/
â”‚       â”œâ”€â”€ sail-seg/                     # Modelo de segmentaciÃ³n
â”‚       â”‚   â”œâ”€â”€ model.json
â”‚       â”‚   â””â”€â”€ weights.bin
â”‚       â””â”€â”€ scene-classifier/             # Modelo de clasificaciÃ³n
â”‚           â”œâ”€â”€ model.json
â”‚           â””â”€â”€ weights.bin
```

### 5.2 Pipeline de detecciÃ³n

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    AUTO-DETECTION PIPELINE                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. SCENE CLASSIFICATION                                         â”‚
â”‚    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                         â”‚
â”‚    Input: imagen completa                                       â”‚
â”‚    Output: ONBOARD_SAIL | CHASE_SAIL | MAST_BEND | UNKNOWN      â”‚
â”‚    Modelo: MobileNet fine-tuned (ligero)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. SAIL SEGMENTATION                                            â”‚
â”‚    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                           â”‚
â”‚    Input: imagen + tipo de escena                               â”‚
â”‚    Output: mÃ¡scara binaria de la vela                           â”‚
â”‚    Modelo: U-Net lite o DeepLab Mobile                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. EDGE EXTRACTION                                              â”‚
â”‚    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                             â”‚
â”‚    Input: mÃ¡scara de vela                                       â”‚
â”‚    Output: luff, leech, foot (polilÃ­neas)                       â”‚
â”‚    Algoritmo: Contour detection + clasificaciÃ³n geomÃ©trica      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. STRIPE DETECTION                                             â”‚
â”‚    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                             â”‚
â”‚    Input: regiÃ³n de vela + imagen original                      â”‚
â”‚    Output: draft stripes detectadas                             â”‚
â”‚    Algoritmo: Color clustering + line detection (Hough)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. CONFIDENCE CHECK                                             â”‚
â”‚    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                             â”‚
â”‚    Si confidence < 70%:                                         â”‚
â”‚      â†’ Fallback a semi-automÃ¡tico (Fase 4A)                     â”‚
â”‚      â†’ Mostrar warning al usuario                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5.3 API

```typescript
// === sail-segmenter.ts ===
export interface SegmentationResult {
  mask: ImageData                    // MÃ¡scara binaria
  boundingBox: BoundingBox
  contour: NormalizedPoint[]
  confidence: number
}

export async function segmentSail(
  imageData: ImageData
): Promise<SegmentationResult | null>

// === stripe-detector.ts ===
export interface DetectedStripe {
  points: NormalizedPoint[]
  estimatedHeightPct: number
  dominantColor: { h: number; s: number; l: number }
  confidence: number
}

export async function detectStripes(
  imageData: ImageData,
  sailMask: ImageData
): Promise<DetectedStripe[]>

// === scene-classifier.ts ===
export interface ClassificationResult {
  sceneType: SceneType
  confidence: number
  probabilities: Record<SceneType, number>
}

export async function classifyScene(
  imageData: ImageData
): Promise<ClassificationResult>

// === Orquestador principal ===
export interface AutoDetectionInput {
  imagePath: string
  hints?: {
    expectedSceneType?: SceneType
    sailColors?: string[]          // Colores conocidos de las stripes
  }
}

export interface AutoDetectionOutput {
  success: boolean
  sceneType: SceneType
  sailRegion?: SegmentationResult
  edges?: {
    luff?: NormalizedPoint[]
    leech?: NormalizedPoint[]
  }
  stripes?: DetectedStripe[]
  overallConfidence: number
  needsManualReview: boolean
}

export async function runAutoDetection(
  input: AutoDetectionInput
): Promise<AutoDetectionOutput>
```

## 6) Algoritmos especÃ­ficos

### 6.1 DetecciÃ³n de Draft Stripes

Las draft stripes suelen tener colores distintivos (rojo, azul, negro sobre vela blanca).

```
1. Convertir imagen a HSL dentro de la mÃ¡scara de vela
2. Aplicar K-means clustering (k=5) para encontrar colores dominantes
3. Filtrar clusters por saturaciÃ³n (stripes suelen ser saturadas)
4. Para cada cluster de color "stripe":
   a. Crear mÃ¡scara binaria del color
   b. Aplicar Hough Line Transform
   c. Agrupar lÃ­neas paralelas cercanas
   d. Extraer polilÃ­nea central
5. Ordenar stripes por posiciÃ³n Y (altura en la vela)
6. Estimar heightPct basÃ¡ndose en posiciÃ³n relativa
```

### 6.2 ClasificaciÃ³n de Bordes (Luff vs Leech)

```
1. Extraer contorno de la mÃ¡scara de vela
2. Encontrar los 3 vÃ©rtices principales (tack, head, clew)
3. Clasificar por geometrÃ­a:
   - Luff: borde mÃ¡s vertical (conecta tackâ†’head)
   - Leech: borde posterior (conecta headâ†’clew)
   - Foot: borde inferior (conecta tackâ†’clew)
4. Para ONBOARD_SAIL: luff estÃ¡ cerca del mÃ¡stil (izquierda tÃ­picamente)
5. Para CHASE_SAIL: luff es el borde de barlovento
```

### 6.3 Modelo de SegmentaciÃ³n

Opciones (ordenadas por preferencia):

1. **DeepLab v3 MobileNet** (recomendado)
   - TamaÃ±o: ~8MB
   - Velocidad: ~100ms en WebGL
   - Pre-entrenado en COCO, fine-tune con dataset de velas

2. **U-Net Lite**
   - TamaÃ±o: ~5MB
   - MÃ¡s simple de entrenar
   - Requiere dataset custom

3. **BodyPix modificado**
   - Ya disponible en TensorFlow.js
   - Requiere adaptaciÃ³n para velas

## 7) Flujo de usuario

### 7.1 Modo automÃ¡tico

1. Usuario importa foto
2. Sistema ejecuta auto-detecciÃ³n en background
3. Al abrir la foto:
   - Si confianza > 70%: muestra resultados automÃ¡ticos
   - Si confianza < 70%: muestra warning + sugiere modo semi-automÃ¡tico
4. Usuario revisa y ajusta si es necesario
5. Guarda anÃ¡lisis

### 7.2 UI Indicators

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ [ğŸ“· Photo Name]                                                  â”‚
â”‚                                                                  â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚                                         â”‚ â”‚ AUTO-DETECTION  â”‚ â”‚
â”‚ â”‚                                         â”‚ â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚ â”‚
â”‚ â”‚          [Photo with overlays]          â”‚ â”‚ Scene: ONBOARD  â”‚ â”‚
â”‚ â”‚                                         â”‚ â”‚ Confidence: 89% â”‚ â”‚
â”‚ â”‚     ~~~~ Detected stripe 1 ~~~~         â”‚ â”‚                 â”‚ â”‚
â”‚ â”‚                                         â”‚ â”‚ âœ“ Sail detected â”‚ â”‚
â”‚ â”‚     ~~~~ Detected stripe 2 ~~~~         â”‚ â”‚ âœ“ 3 stripes     â”‚ â”‚
â”‚ â”‚                                         â”‚ â”‚ âœ“ Luff found    â”‚ â”‚
â”‚ â”‚     ~~~~ Detected stripe 3 ~~~~         â”‚ â”‚ âš  Leech unclear â”‚ â”‚
â”‚ â”‚                                         â”‚ â”‚                 â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ [Use Results]   â”‚ â”‚
â”‚                                             â”‚ [Manual Mode]   â”‚ â”‚
â”‚                                             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## 8) Consideraciones de rendimiento

### 8.1 Carga de modelos
- Modelos se cargan lazy (primera vez que se usa auto-detection)
- Cachear en IndexedDB para cargas posteriores
- Mostrar progreso de descarga

### 8.2 Inferencia
- Usar WebGL backend cuando estÃ© disponible
- Fallback a WASM si WebGL no funciona
- Procesar en web worker para no bloquear UI
- Target: < 2 segundos para pipeline completo

### 8.3 TamaÃ±o de modelos
- Total de modelos: < 20MB
- CompresiÃ³n con quantization (int8)

## 9) Criterios de aceptaciÃ³n

### Must Have
- [ ] TensorFlow.js carga correctamente en Electron
- [ ] ClasificaciÃ³n de escena funciona con >80% accuracy en fotos tÃ­picas
- [ ] SegmentaciÃ³n detecta la vela en >70% de los casos
- [ ] Fallback a semi-automÃ¡tico cuando confianza es baja
- [ ] Funciona offline despuÃ©s de primera carga de modelos

### Should Have
- [ ] DetecciÃ³n de draft stripes por color
- [ ] ClasificaciÃ³n automÃ¡tica de luff/leech
- [ ] Indicador de confianza por cada elemento detectado
- [ ] Procesamiento en background al importar fotos

### Nice to Have
- [ ] Mejora continua: reentrenar con correcciones del usuario
- [ ] DetecciÃ³n de mÃºltiples velas (ej. gÃ©nova + mayor)
- [ ] Sugerencia automÃ¡tica de sail ID basada en tipo detectado

## 10) Dataset y entrenamiento

### 10.1 Dataset necesario
Para fine-tuning se necesitan ~500-1000 imÃ¡genes anotadas:
- Fotos ONBOARD_SAIL con mÃ¡scaras de vela
- Fotos CHASE_SAIL con mÃ¡scaras de vela
- Anotaciones de luff/leech/stripes

### 10.2 Opciones de obtenciÃ³n
1. Anotar manualmente con herramienta como LabelMe
2. Usar datos generados por usuarios (con consentimiento)
3. Generar sintÃ©ticamente (3D render de velas)
4. Colaborar con veleros/equipos que compartan datos

### 10.3 Entrenamiento
- Usar Google Colab o similar para entrenar
- Exportar modelo a TensorFlow.js format
- Incluir script de conversiÃ³n en el repo

## 11) Riesgos y mitigaciones

| Riesgo | Probabilidad | Impacto | MitigaciÃ³n |
|--------|--------------|---------|------------|
| No hay dataset suficiente | Alta | Alto | Empezar con modelo genÃ©rico, mejorar con uso |
| Modelos demasiado grandes | Media | Medio | Quantization, pruning, modelos mobile |
| Baja accuracy en fotos reales | Media | Alto | Fallback obligatorio a semi-automÃ¡tico |
| WebGL no disponible | Baja | Medio | Fallback a WASM (mÃ¡s lento pero funciona) |

## 12) Dependencias

```json
{
  "dependencies": {
    "@tensorflow/tfjs": "^4.x",
    "@tensorflow/tfjs-backend-wasm": "^4.x",
    "@tensorflow/tfjs-backend-webgl": "^4.x"
  }
}
```

## 13) RelaciÃ³n con otras fases

- **Requiere**: Fase 4A (usa edge detection como fallback)
- **Habilita**: Fase 5 (mÃ©tricas automÃ¡ticas sin intervenciÃ³n)
- **Mejora**: Fase 6 (comparaciones mÃ¡s rÃ¡pidas con auto-detection)
